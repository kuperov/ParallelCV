{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal PCV example: single Poisson model (fully online inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we estimate the predictive density for a simple Poisson regression using leave-one-out cross-validation. There is no model selection, we are simply measuring predictive ability.\n",
    "\n",
    "Of course, this problem does not require parallel sampling. However, it is a very simple model where it makes sense to use CV, so we use it to demonstrate the method.\n",
    "\n",
    "This standalone notebook depends only on JAX, Blackjax, and matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCV implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.special import logsumexp\n",
    "import blackjax as bj\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel sampler for PCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcv_LogS_sampler_online(key, log_dens_fn, log_pred_fn, init_pos, C_k, L, H, G, D, kparam):\n",
    "    \"\"\"Sampler for parallel cross-validation using LogS for a single model.\n",
    "    \n",
    "    Generates the statistics required to estimate ESS, MCSE, Rhat_max, and\n",
    "    the Rhat_max benchmark. Space complexity is O(K*L*D), independent of\n",
    "    G and H and therefore constant with respect to MCMC chain length.\n",
    "\n",
    "    Args:\n",
    "        key: JAX PRNG key array\n",
    "        log_dens_fn: log density function with signature (params, fold_id)\n",
    "        log_pred_fn: log predictive density function with signature (params, fold_id)\n",
    "        init_pos: K*L*p pytree of initial positions for each fold and chain\n",
    "        C_k: K-array of centering constants per fold\n",
    "        L: number of chains\n",
    "        H: MCMC draws per batch\n",
    "        G: number of batches per block\n",
    "        D: number of shuffle blocks\n",
    "        kparam: dictionary of hyperparameters for Blackjax HMC kernel\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (last_state, Ux, Ux2, Vx, Vx2, Yx, Yx2, E)\n",
    "    \"\"\"\n",
    "    K = C_k.shape[0]\n",
    "\n",
    "    def run_chain(init_pos, chain_key, fold_id, C):  # sample from a single chain\n",
    "        fold_log_dens_fn = lambda params: log_dens_fn(params, fold_id)\n",
    "        hmc_kernel = bj.hmc(fold_log_dens_fn, **kparam)\n",
    "\n",
    "        def mcmc_step(carry_state, _): # a single mcmc step\n",
    "            key, prev_state, Zx, Ux2, E, Yx, Yx2 = carry_state\n",
    "            step_key, carry_key = jax.random.split(key)\n",
    "            state, info = hmc_kernel.step(step_key, prev_state)  # one mcmc step\n",
    "            lpred = log_pred_fn(state.position, fold_id)  # cond. log predictive\n",
    "            E = E + info.is_divergent\n",
    "            Zx = jnp.logaddexp(Zx, lpred)  # increment accumulators\n",
    "            Ux2 = jnp.logaddexp(Ux2, 2*lpred)\n",
    "            Yx += lpred - C\n",
    "            Yx2 += (lpred - C)**2\n",
    "            return (carry_key, state, Zx, Ux2, E, Yx, Yx2), None\n",
    "\n",
    "        def batch_step(batch_carry, _): # one batch of H mcmc steps\n",
    "            key, init_state, Ux, Ux2, Vx, Vx2, E, Yx, Yx2 = batch_carry\n",
    "            init_carry = (key, init_state, -jnp.inf, Ux2, E, Yx, Yx2)\n",
    "            (carry_key, state, Zx, Ux2, E, Yx, Yx2), _ = \\\n",
    "                jax.lax.scan(mcmc_step, init_carry, None, length=H)\n",
    "            Zx_bar = Zx - jnp.log(H)  # this batch mean\n",
    "            Vx = jnp.logaddexp(Vx, Zx_bar)  # increment accumulators\n",
    "            Vx2 = jnp.logaddexp(Vx2, 2*Zx_bar)\n",
    "            Ux = jnp.logaddexp(Ux, Zx)\n",
    "            return (carry_key, state, Ux, Ux2, Vx, Vx2, E, Yx, Yx2), None\n",
    "\n",
    "        def block_step(block_carry, _): # one block of G batches\n",
    "            init_carry = block_carry + (0, 0,)  # zeros are (Yx, Yx2)\n",
    "            (key, prev_state, Ux, Ux2, Vx, Vx2, E, Yx, Yx2), _ = \\\n",
    "                jax.lax.scan(batch_step, init_carry, None, length=G)\n",
    "            return (key, prev_state, Ux, Ux2, Vx, Vx2, E), (Yx, Yx2)\n",
    "\n",
    "        init_state = hmc_kernel.init(init_pos)\n",
    "        init_carry = (chain_key, init_state, -jnp.inf, -jnp.inf, -jnp.inf, -jnp.inf,  0)\n",
    "        #                                        (Ux),    (Ux2),     (Vx),    (Vx2), (E)\n",
    "        return jax.lax.scan(block_step, init_carry, None, length=D)\n",
    "\n",
    "    def run_fold(fold_key, ch_init_pos, fold_id, C): # run L chains for one fold\n",
    "        sampling_fn = jax.vmap(lambda pos, key: run_chain(pos, key, fold_id, C))\n",
    "        return sampling_fn(ch_init_pos, jax.random.split(fold_key, L))\n",
    "\n",
    "    (_, last_state, Ux, Ux2, Vx, Vx2, E), (Yx, Yx2) = \\\n",
    "        jax.vmap(run_fold)(jax.random.split(key, K), init_pos, jnp.arange(K), C_k)\n",
    "    return (last_state, Ux, Ux2, Vx, Vx2, Yx, Yx2, E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for computing the (log of the) variance from welford statistics. We use logs to numerically stabilize calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_var(n, log_sum_X, log_sum_X2):  # log variance from welford states\n",
    "    return (-jnp.log(n - 1) + log_sum_X2 \n",
    "        + jnp.log1p(-jnp.exp(2 * log_sum_X - jnp.log(n) - log_sum_X2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute $\\widehat{R}$ from welford statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_rhats(Yx_kl, Yx2_kl, N):\n",
    "    \"\"\"Compute rhat statistics per chain using welford statistics\n",
    "    \n",
    "    Args:\n",
    "        Yx_kl: K*L array of centered sum of log predictive densities per chain\n",
    "        Yx2_kl: K*L array of sum of centered squared log predictive densities per chain\n",
    "        N: number of samples per chain\n",
    "    \n",
    "    Returns:\n",
    "        K-vector of rhat statistics\n",
    "    \"\"\"\n",
    "    assert Yx_kl.shape == Yx2_kl.shape\n",
    "    W = ((Yx2_kl - N*(Yx_kl/N)**2)/(N-1)).mean(axis=1)\n",
    "    B = N*(Yx_kl/N).var(axis=1, ddof=1)\n",
    "    V = W*(N-1)/N + B/N\n",
    "    return jnp.sqrt(V/W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute shuffled $\\widehat{R}_{max}$ draws, i.e. the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled_rhat_maxs(key, Yx, Yx2, N, num_shuffles):\n",
    "    \"\"\"Simulate Rhat_max for synthetic mixed chains by shuffling blocks\n",
    "    \n",
    "    Args:\n",
    "        key: jax.random.PRNGKey\n",
    "        Ux: K*L*D array of log sum of predictive densities per fold, chain, and block\n",
    "        Ux2: K*L*D array of log sum of square predictive densities per fold, chain, and block\n",
    "        N: number of samples per chain\n",
    "        num_shuffles: number of shuffles to draw\n",
    "    \"\"\"\n",
    "    K, L, D = Yx.shape\n",
    "    assert Yx.shape == Yx2.shape\n",
    "    def shuffle_welford_stats(block_lS, shuff_key):\n",
    "        def shuffle_chains(shuff_key, k, s):\n",
    "            return jax.random.choice(shuff_key, block_lS[k, :, s], shape=(L,))\n",
    "        def shuffle_fold(shuff_key, k):\n",
    "            keys = jax.random.split(shuff_key, D)\n",
    "            shuffled = jax.vmap(shuffle_chains, in_axes=(0,None,0))(keys, k, jnp.arange(D))\n",
    "            return shuffled.sum(axis=0)  # stats for synthetic chains\n",
    "        return jax.vmap(shuffle_fold)(jax.random.split(shuff_key, K), jnp.arange(K))\n",
    "    def draw(draw_key):\n",
    "        # note common keys so shuffling generates same order for both stats\n",
    "        sUx = shuffle_welford_stats(Yx, draw_key)\n",
    "        sUx2 = shuffle_welford_stats(Yx2, draw_key)\n",
    "        return online_rhats(sUx, sUx2, N).max()\n",
    "    return jax.vmap(draw)(jax.random.split(key, num_shuffles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All-in-one function to do initial adaptation, full-data sampling, parallel warmup, parallel sampling, then compute statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_pcv_LogS(key, log_dens_fn, log_pred_fn, init_pos, K, L, H, G, D, N_delta, N_fd):\n",
    "    \"\"\"\n",
    "    Basic parallel cross-validation using LogS and Hamiltonian Monte Carlo (HMC)\n",
    "\n",
    "    This variant performs full-data sampling, parallel warmup, parallel sampling,\n",
    "    and computes summaries, all in one function.\n",
    "\n",
    "    Args:\n",
    "        key: JAX PRNG key array\n",
    "        log_dens_fn: log density function with signature (params, fold_id)\n",
    "        log_pred_fn: log predictive density function with signature (params, fold_id)\n",
    "        init_pos: initial position for a single chain\n",
    "        K: number of folds\n",
    "        L: number of chains\n",
    "        H: MCMC draws per batch\n",
    "        G: number of batches per block\n",
    "        D: number of shuffle blocks\n",
    "        N_delta: number of samples for estimating CV se\n",
    "        N_fd: Number of samples for full-data posterior\n",
    "    \"\"\"\n",
    "    N = G*D*H  # number of samples per chain\n",
    "\n",
    "    warmup_k1, warmup_k2, warmup_k3, warmup_k4, sampling_key, shuff_key = jax.random.split(key, 6)\n",
    "\n",
    "    # Stan-style window adaptation HMC warmup\n",
    "    full_data_dens = lambda x: log_dens_fn(x, -1)\n",
    "    res, _ = (bj\n",
    "                 .window_adaptation(bj.hmc, full_data_dens, num_integration_steps=5)\n",
    "                 .run(warmup_k1, init_pos))\n",
    "    kparam = res.parameters\n",
    "\n",
    "    # Draw initial samples from full-data posterior - for simplicity use a single chain\n",
    "    fd_kernel = bj.hmc(full_data_dens, **kparam)\n",
    "    def inference_loop(params, key):\n",
    "        params, _ = fd_kernel.step(key, params)\n",
    "        return params, params.position\n",
    "    sampling_keys = jax.random.split(warmup_k2, N_fd)\n",
    "    _, init_pos = jax.lax.scan(inference_loop, res.state, sampling_keys)\n",
    "\n",
    "    initial_idxs = jax.random.choice(warmup_k3, jnp.arange(init_pos.shape[0]), shape=(K,L,))\n",
    "    ch_init_pos = init_pos[initial_idxs, :]\n",
    "\n",
    "    sample = jax.jit(lambda key, pos, C_k: pcv_LogS_sampler_online(key, log_dens_fn, log_pred_fn, pos, C_k, L, H, G, D, kparam))\n",
    "    warm_states, _, _, _, _, Yx_wu, _, _ = sample(warmup_k4, ch_init_pos, jnp.zeros(K))  # parallel warmup\n",
    "    C_k = Yx_wu.sum(axis=(1,2))/(L*N)  # sum over chains and blocks\n",
    "    _, Ux, Ux2, Vx, Vx2, Yx, Yx2, E = sample(sampling_key, warm_states.position, C_k)  # parallel sampling\n",
    "\n",
    "    # sum over blocks to get chain-level statistics\n",
    "    Yx_k = Yx.sum(axis=2)\n",
    "    Yx2_k = Yx2.sum(axis=2)\n",
    "\n",
    "    # effective sample size (ess)\n",
    "    log_ssq_k = log_var(L*N, logsumexp(Ux, axis=1), logsumexp(Ux2, axis=1))\n",
    "    log_sigsq_k = jnp.log(H) + log_var(L*N//H, logsumexp(Vx, axis=1), logsumexp(Vx2, axis=1))\n",
    "    ess = N * L * jnp.exp(logsumexp(log_ssq_k) - logsumexp(log_sigsq_k))\n",
    "\n",
    "    # Expected log predictive density (elpd)\n",
    "    log_phat_k = logsumexp(Ux, axis=1) - jnp.log(L*N)\n",
    "    elpd = log_phat_k.sum()\n",
    "\n",
    "    # Monte Carlo standard error (mcse)\n",
    "    log_var_phat_k = log_ssq_k - jnp.log(L*N)  # log variance of mean density\n",
    "    log_var_etahat_k = log_var_phat_k - 2*log_phat_k  # log var of log mean density (delta method)\n",
    "    elpd_mcse = jnp.exp(0.5*logsumexp(log_var_etahat_k))  # sum of independent variances\n",
    "\n",
    "    # CV standard error (cvse) by simulation with (truncated) normal mean density assumption\n",
    "    log_scale_coef_k = jnp.expand_dims(-0.5 * log_var_phat_k, axis=1)\n",
    "    sim_mean_k = jnp.exp(jnp.expand_dims(log_phat_k, axis=1) + log_scale_coef_k)\n",
    "    scaled_draw_k_i = sim_mean_k + jax.random.truncated_normal(key=key, lower=-sim_mean_k, upper=jnp.inf, shape=(K, N_delta))\n",
    "    draw_cvvar_i = jnp.var(jnp.log(scaled_draw_k_i) - log_scale_coef_k, axis=0)  # cv var draws\n",
    "    cvse = jnp.sqrt(jnp.mean(draw_cvvar_i))\n",
    "\n",
    "    # Rhat_max mixing statistic and benchmark\n",
    "    rhat_max = online_rhats(Yx_k, Yx2_k, N).max()\n",
    "    shuff_rhat_maxs = shuffled_rhat_maxs(shuff_key, Yx, Yx2, N, 500)\n",
    "    q_rhat_max = jnp.mean(rhat_max >= shuff_rhat_maxs)\n",
    "\n",
    "    print(f\"{K} folds generated {L*N} draws each ({L} chains * {N} iter, {L*N//H} batches of {H})\")\n",
    "    print(f\"elpdhat: {elpd:.4f} (mcse {elpd_mcse:.4f}, CV se {cvse:.4f})\")\n",
    "    print(f\"overall ess: {ess:.0f}\")\n",
    "    print(f\"rhat_max: {rhat_max:.4f} (q = {q_rhat_max*100:.0f}%)\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,2.5))\n",
    "    ax.hist(shuff_rhat_maxs[jnp.isfinite(shuff_rhat_maxs)], bins=20)\n",
    "    ax.axvline(rhat_max, color='red')\n",
    "    ax.ticklabel_format(useOffset=False)\n",
    "    ax.set_title(r'$\\widehat{R}_{max}$ and emulated mixed benchmark')\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and inference\n",
    "\n",
    "The model is\n",
    "$$ y_i | x_i, \\beta \\sim \\mathrm{pois}\\left(\\exp\\left(x_i^\\top\\beta\\right)\\right), \\qquad i=1,\\dots,N, $$\n",
    "and we impose a spherical normal prior, $ \\beta_j \\sim \\mathcal{N}\\left(0,1\\right),\\ j=1,\\dots,p $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)  # use double precision\n",
    "\n",
    "# generate data for poisson regression model\n",
    "data_key = jax.random.PRNGKey(seed=42) # data seed\n",
    "p = 5  # regressors including the constant\n",
    "n_obs = 50  # number of observations\n",
    "beta_true = jnp.array([1., 1., 1., 0., 0.])\n",
    "data_k1, data_k2 = jax.random.split(data_key)\n",
    "X = jnp.hstack([\n",
    "    jnp.ones((n_obs,1)),\n",
    "    jax.random.normal(key=data_k1, shape=(n_obs, p-1))])\n",
    "y = jax.random.poisson(key=data_k2, lam=jnp.exp(X @ beta_true))\n",
    "\n",
    "# log density function, by fold\n",
    "def log_dens_fn(params, fold_id):\n",
    "    mask = jnp.arange(n_obs) != fold_id  # LOO-CV, use -1 for full data\n",
    "    return (jax.scipy.stats.poisson.logpmf(y, jnp.exp(X @ params)) * mask).sum()\n",
    "\n",
    "# conditional predictive function, by fold\n",
    "def log_pred_fn(params, fold_id):\n",
    "    return jax.scipy.stats.poisson.logpmf(y[fold_id], jnp.exp(X[fold_id] @ params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform parallel cross-validation to estimate predictive ability under LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 folds generated 4000 draws each (4 chains * 1000 iter, 80 batches of 50)\n",
      "elpdhat: -87.8131 (mcse 0.0316, CV se 0.9501)\n",
      "overall ess: 2796\n",
      "rhat_max: 1.0020 (q = 77%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_pcv_LogS(\n",
    "    key= jax.random.PRNGKey(seed=123),  # inference seed\n",
    "    log_dens_fn=log_dens_fn,  # log density function, by fold\n",
    "    log_pred_fn=log_pred_fn,  # conditional predictive function, by fold\n",
    "    init_pos=jnp.zeros(p),  # initial mcmc warmup position\n",
    "    K=n_obs,  # number of folds (LOO-CV)\n",
    "    L=4,  # number of chains\n",
    "    H=50,  # batch size\n",
    "    G=5,  # batches per shuffle block\n",
    "    D=4,  # shuffle blocks\n",
    "    N_delta=500,  # CV se estimation draws\n",
    "    N_fd=500  # full-data mcmc draws\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
