{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of concept - online rhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blackjax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "from collections import namedtuple\n",
    "from blackjax.diagnostics import potential_scale_reduction\n",
    "import matplotlib.pyplot as plt\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfpk = tfp.math.psd_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta = namedtuple('Theta', ['beta', 'sigsq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WelfordState = namedtuple(\"WelfordState\", [\"K\", \"Ex\", \"Ex2\", \"n\"])\n",
    "\n",
    "def welford_init(K) -> WelfordState:\n",
    "  return WelfordState(K, 0., 0., 0)\n",
    "\n",
    "def welford_add(state: WelfordState, x: float) -> WelfordState:\n",
    "  return WelfordState(state.K, state.Ex + x - state.K, state.Ex2 + (x - state.K)**2, state.n + 1)\n",
    "\n",
    "def welford_mean(state: WelfordState) -> WelfordState:\n",
    "  return state.K + state.Ex / state.n\n",
    "\n",
    "def welford_var(state: WelfordState) -> WelfordState:\n",
    "  return (state.Ex2 - state.Ex**2 / state.n) / (state.n - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtendedState = namedtuple(\"ExtendedState\", ['state', 'welford_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_key, X_key = jax.random.split(jax.random.PRNGKey(0))\n",
    "N = 100\n",
    "beta0 = jnp.array([1.0, 2.0, 3.0, 4.0])\n",
    "p = len(beta0)\n",
    "sigsq0 = jnp.array(2.0)\n",
    "X = tfd.Normal(loc=0, scale=1).sample(sample_shape=(N, p), seed=X_key)\n",
    "y = X@beta0 + tfd.Normal(loc=0, scale=jnp.sqrt(sigsq0)).sample(sample_shape=(N,), seed=y_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use exp to transform sigsq to unconstrained space\n",
    "sigsq_t = tfb.Exp()\n",
    "\n",
    "beta_prior = tfd.MultivariateNormalDiag(loc=jnp.zeros(p), scale_diag=jnp.ones(p))\n",
    "sigsq_prior = tfd.Gamma(concentration=1.0, rate=1.0)\n",
    "\n",
    "def logprob_fn(theta: Theta):\n",
    "  sigsq = sigsq_t.forward(theta.sigsq)\n",
    "  sigsq_ldj = sigsq_t.forward_log_det_jacobian(theta.sigsq)\n",
    "  lprior = beta_prior.log_prob(theta.beta) + sigsq_prior.log_prob(theta.sigsq)\n",
    "  lhood = tfd.Normal(loc=X@theta.beta, scale=jnp.sqrt(sigsq)).log_prob(y).sum()\n",
    "  return lprior + lhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "warmup_iter = 500\n",
    "num_chains = 5\n",
    "warmup_key, sampling_key, init_key, subs_key = jax.random.split(jax.random.PRNGKey(0), 4)\n",
    "\n",
    "# random initialization in the constrained parameter space\n",
    "def make_initial_pos(key):\n",
    "  k1, k2 = jax.random.split(key)\n",
    "  return Theta(beta=jax.random.normal(key=k1, shape=(p,)), sigsq=jax.random.normal(key=k2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "warmup = blackjax.window_adaptation(blackjax.nuts, logprob_fn, num_steps=warmup_iter, progress_bar=True)\n",
    "final_warmup_state, kernel, info = warmup.run(warmup_key, make_initial_pos(init_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample initial positions from second half of warmup trajectory\n",
    "idxs = jax.random.choice(subs_key, a=jnp.arange(warmup_iter//2, warmup_iter), shape=(num_chains,))\n",
    "initial_positions = Theta(\n",
    "    beta = info[0].position.beta[idxs,],\n",
    "    sigsq = info[0].position.sigsq[idxs]\n",
    ")\n",
    "initial_states = jax.vmap(lambda p: blackjax.nuts.init(p, logprob_fn))(initial_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sense check logprob_fn\n",
    "[logprob_fn(final_warmup_state.position), jax.vmap(logprob_fn)(initial_positions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(info[0].position.beta)\n",
    "plt.title('beta warmup')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(info[0].position.sigsq)\n",
    "plt.title('sigsq warmup')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_loop(rng_key, kernel, initial_state, num_samples):\n",
    "\n",
    "    @jax.jit\n",
    "    def one_step(state, rng_key):\n",
    "        state, _ = kernel(rng_key, state)\n",
    "        e = X @ state.position.beta - y\n",
    "        elpd = -0.5 * (\n",
    "            jnp.log(2 * jnp.pi)\n",
    "            + jnp.log(state.position.sigsq)\n",
    "            + jnp.dot(e, e)/state.position.sigsq\n",
    "        )\n",
    "        return state, state\n",
    "\n",
    "    keys = jax.random.split(rng_key, num_samples)\n",
    "    _, states = jax.lax.scan(one_step, initial_state, keys)\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sampling_keys = jax.random.split(sampling_key, num_chains)\n",
    "\n",
    "states = jax.vmap(inference_loop, in_axes=(0, None, 0, None))(\n",
    "    sampling_keys, kernel, initial_states, num_samples)\n",
    "_ = states.position.sigsq[0,0].block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "sigsq = sigsq_t.forward(states.position.sigsq)\n",
    "print(f\"E[sigsq|y] = {jnp.mean(sigsq, axis=(0,1)).round(3)}\")\n",
    "print(f\"E[beta|y]  = {jnp.mean(states.position.beta, axis=(0,1)).round(3)}\")\n",
    "# diagnostics\n",
    "print(f\"beta rhat  = {potential_scale_reduction(states.position.beta).round(3)}\")\n",
    "print(f\"sigsq rhat = {potential_scale_reduction(states.position.sigsq).round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicate rhat for sigsq, easier because univariate\n",
    "\n",
    "# notation from Vats et al\n",
    "\n",
    "n = states.position.sigsq.shape[1]\n",
    "m = states.position.sigsq.shape[0]\n",
    "print(f\"n = {n}, m = {m}\")\n",
    "# mean of individual chain sample variances\n",
    "chain_sample_variances = jnp.var(states.position.sigsq, ddof=1, axis=1)\n",
    "print(f\"s_m^2 = {chain_sample_variances}\")\n",
    "W = jnp.mean(chain_sample_variances)\n",
    "print(f\"W = {W}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_means = jnp.mean(states.position.sigsq, axis=1)\n",
    "print(f\"chain_means = {chain_means}\")\n",
    "B = n*jnp.var(chain_means, ddof=1)\n",
    "print(f\"B = {B}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b244e6cf922c9b0621775d312a136f9c0e093f5a4d6569bbfcf3ecc99e4276f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
